{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sai23d/CS345_FinalProject/blob/main/DSCI521_Final_Project_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQOyYK9E7qoU"
      },
      "source": [
        "### College of Computing and Informatics, Drexel University\n",
        "### DSCI 521: Data Analysis and Interpretation\n",
        "---\n",
        "\n",
        "## Final Project Report\n",
        "\n",
        "## Project Title:\n",
        "\n",
        "## Student(s):\n",
        "\n",
        "## Date:\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mMpIyk672Ah"
      },
      "source": [
        "## Your project should include the following components:\n",
        "- Problem Definition: Define a clear problem or task to solve using data analysis techniques.\n",
        "\n",
        "- Dataset Selection: You must choose a dataset relevant to your interests or a specific domain. The dataset should be of sufficient size and complexity to demonstrate various data analysis techniques.\n",
        "\n",
        "- Exploratory Data Analysis (EDA): You need to perform thorough EDA on the dataset to understand its characteristics, identify patterns, missing values, outliers, and potential features for modeling.\n",
        "\n",
        "- Feature Engineering: Implement feature engineering for creating new features, transforming existing ones, or selecting relevant features.\n",
        "\n",
        "- Model Evaluation and Selection: Experiment with different data analysis algorithms and techniques. Evaluate the models using appropriate evaluation metrics\n",
        "\n",
        "- Conclusion: Discuss your findings and future work.\n",
        "\n",
        "## You should write the report with following characristics to ensure effective communication:\n",
        "- Visualization and Interpretation: You should use visulization throughout EDA, modeling, and evaluation to illustrate any insights.\n",
        "\n",
        "- Code and Implementation: Throughout the notebook, you must write well-structured and commented code.\n",
        "\n",
        "- Documentation and Presentation: Throughout the notebook, you must add comprehensive commentary text to explain plots and code snippets. Always provide interpretations and explanations to document your analyses and results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKZnMElj7qoW"
      },
      "source": [
        "### 1. Problem Definition\n",
        "---\n",
        "*(Define the problem that will be solved in this data analytics project.)*\n",
        "\n",
        "This project focuses on the key question:\n",
        "\n",
        "How do socioeconomic factors affect access to the internet and digital devices across U.S. communities? While we know that digital access is often worse in disadvantaged areas, this project uses recent data from the American Community Survey (ACS) 5-Year Estimates to measure these patterns more precisely.(2018-2022) We will: Identify areas (census tracts) with low digital access, such as households without internet or computers. Explore how factors like income, education, and housing costs relate to digital access. Build models to predict which communities are most likely to face digital exclusion and which factors matter most. Our goal is to better understand how inequality impacts digital access and provide useful insights for decision-makers working to close the digital gap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzLEXU-t7qoW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW-Znace7qoW"
      },
      "source": [
        "### 2. Data Sets\n",
        "---\n",
        "*(Describe the origin of the data sources. What is the format of the original data? How to access the data?)*\n",
        "\n",
        "The primary dataset used in this project comes from the American Community Survey (ACS) 5-Year Estimates, conducted by the U.S. Census Bureau. The ACS is an ongoing nationwide survey that collects detailed population and housing information from approximately 3.5 million addresses each year. The 5-year estimates aggregate data over five years to provide reliable statistics at small geographic levels such as census tracts and other geographic levels.\n",
        "\n",
        "In this project, we focus on variables related to:\n",
        "\n",
        "Digital access (e.g., internet subscriptions, device availability) Socioeconomic status (e.g., household income, education level, rent burden) Demographic context (e.g., total population, age, race) These data are widely used in policy planning, academic research, and social service allocation.\n",
        "\n",
        "Format of the Data: The ACS data are provided in multiple formats:\n",
        "\n",
        "CSV (Comma-Separated Values) files — for individual tables (e.g., B28002, B19013) API Access — via the U.S. Census Bureau API for automated querying\n",
        "\n",
        "Each dataset includes:\n",
        "\n",
        "A GEOID column (unique geographic identifier) Estimate and Margin of Error (MOE) columns for each variable Metadata, including variable labels and geographic definitions\n",
        "\n",
        "There are several ways to access ACS 5-Year Estimates:\n",
        "\n",
        "Census Bureau Website (https://www2.census.gov/programs-surveys/acs/summary_file/) Use the “Advanced Search” to filter by year, geographic level, and table ID (e.g., B28002 for internet access) Download selected tables as CSV files\n",
        "\n",
        "U.S. Census Bureau API Register for a free API key at https://api.census.gov/data/key_signup.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uvBASP9d7qoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5017fb0a-7f71-4d42-bdf6-cd0c3d3917a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: census in /usr/local/lib/python3.12/dist-packages (0.8.24)\n",
            "Requirement already satisfied: us in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: requests>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from census) (2.32.4)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.12/dist-packages (from us) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (2025.8.3)\n",
            "Fetching data for Alabama...\n",
            "Fetching data for Alaska...\n",
            "Fetching data for Arizona...\n",
            "Fetching data for Arkansas...\n",
            "Fetching data for California...\n",
            "Fetching data for Colorado...\n",
            "Fetching data for Connecticut...\n",
            "Fetching data for Delaware...\n",
            "Fetching data for Florida...\n",
            "Fetching data for Georgia...\n",
            "Fetching data for Hawaii...\n",
            "Fetching data for Idaho...\n",
            "Fetching data for Illinois...\n",
            "Fetching data for Indiana...\n",
            "Fetching data for Iowa...\n",
            "Fetching data for Kansas...\n",
            "Fetching data for Kentucky...\n",
            "Fetching data for Louisiana...\n",
            "Fetching data for Maine...\n",
            "Fetching data for Maryland...\n",
            "Fetching data for Massachusetts...\n",
            "Fetching data for Michigan...\n",
            "Fetching data for Minnesota...\n",
            "Fetching data for Mississippi...\n",
            "Fetching data for Missouri...\n",
            "Fetching data for Montana...\n",
            "Fetching data for Nebraska...\n",
            "Fetching data for Nevada...\n",
            "Fetching data for New Hampshire...\n",
            "Fetching data for New Jersey...\n",
            "Fetching data for New Mexico...\n",
            "Fetching data for New York...\n",
            "Fetching data for North Carolina...\n",
            "Fetching data for North Dakota...\n",
            "Fetching data for Ohio...\n",
            "Fetching data for Oklahoma...\n",
            "Fetching data for Oregon...\n",
            "Fetching data for Pennsylvania...\n",
            "Fetching data for Rhode Island...\n",
            "Fetching data for South Carolina...\n",
            "Fetching data for South Dakota...\n",
            "Fetching data for Tennessee...\n",
            "Fetching data for Texas...\n",
            "Fetching data for Utah...\n",
            "Fetching data for Vermont...\n",
            "Fetching data for Virginia...\n",
            "Fetching data for Washington...\n",
            "Fetching data for West Virginia...\n",
            "Fetching data for Wisconsin...\n",
            "Fetching data for Wyoming...\n"
          ]
        }
      ],
      "source": [
        "# ======================================\n",
        "# American Community Survey (ACS) 5-Year Estimates\n",
        "# Project: Digital Divide in U.S. Communities\n",
        "# Year: 2018-2022\n",
        "# ======================================\n",
        "\n",
        "# -----------------------------\n",
        "# 0. Install required packages\n",
        "# -----------------------------\n",
        "!pip install census us pandas matplotlib seaborn scikit-learn\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Import libraries\n",
        "# -----------------------------\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from census import Census\n",
        "from us import states\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Connect to the Census API\n",
        "# -----------------------------\n",
        "API_KEY = \"0b77d873815d425f3098f0c0aa6be4a000493aae\"\n",
        "c = Census(API_KEY)\n",
        "\n",
        "year = 2022  # ACS 5-Year Estimates (2018-2022)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Define variables to pull\n",
        "# -----------------------------\n",
        "variables = {\n",
        "    \"B28002_013E\": \"no_internet\",        # Households without internet\n",
        "    \"B28001_002E\": \"with_computer\",      # Households with computers\n",
        "    \"B19013_001E\": \"median_income\",      # Median household income\n",
        "    \"B15003_017E\": \"high_school\",        # High school grads\n",
        "    \"B15003_022E\": \"bachelors\",          # Bachelor's degree\n",
        "    \"B25070_001E\": \"gross_rent\",         # Rent burden (total households paying rent)\n",
        "    \"B01003_001E\": \"total_population\",   # Total population\n",
        "}\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Pull data for all states and tracts\n",
        "# -----------------------------\n",
        "all_data = []\n",
        "\n",
        "for state in states.STATES:\n",
        "    print(f\"Fetching data for {state.name}...\")\n",
        "    try:\n",
        "        data = c.acs5.state_county_tract(\n",
        "            list(variables.keys()),\n",
        "            state.fips,\n",
        "            \"*\",  # all counties\n",
        "            \"*\",  # all tracts\n",
        "            year=year\n",
        "        )\n",
        "        all_data.extend(data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {state.name}: {e}\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(all_data)\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Create GEOID20 for unique tract ID\n",
        "# -----------------------------\n",
        "df['GEOID20'] = df['state'] + df['county'] + df['tract'].str.zfill(6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY_PvC857qoX"
      },
      "source": [
        "### 3. Exploration and Feature Engineering\n",
        "---\n",
        "*(Describe and present any code and methods used for exploring and visualizing the data, including statistical analysis and examination of correlations between features. Perform feature engineering to support model development.)*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 6) Rename columns and clean ----\n",
        "# Make sure your `variables` dict includes these denominators:\n",
        "# \"B28002_001E\": \"hh_total_inet\",\n",
        "# \"B28001_001E\": \"hh_total_comp\",\n",
        "# \"B15003_001E\": \"edu_total_25p\",\n",
        "df = df.rename(columns={k:v for k,v in variables.items() if k in df.columns}).copy()\n",
        "\n",
        "# numeric casting\n",
        "num_cols = [v for v in variables.values() if v in df.columns]\n",
        "for c in num_cols:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# GEOID hygiene (if not already done)\n",
        "df[\"tract\"] = df[\"tract\"].astype(str).str.zfill(6)\n",
        "df[\"GEOID\"] = df[\"state\"] + df[\"county\"] + df[\"tract\"]\n",
        "\n",
        "# Handle sentinel codes (rare, but safe)\n",
        "df.replace({-666666666: np.nan, -6666666666: np.nan, np.inf: np.nan, -np.inf: np.nan}, inplace=True)\n",
        "\n",
        "# ---- 7) Derived variables (correct denominators) ----\n",
        "# % households with no internet\n",
        "if {\"no_internet\",\"hh_total_inet\"}.issubset(df.columns):\n",
        "    df[\"pct_no_internet\"] = (df[\"no_internet\"] / df[\"hh_total_inet\"]).clip(0, 1)\n",
        "\n",
        "# % households with a computer (optional but useful)\n",
        "if {\"with_computer\",\"hh_total_comp\"}.issubset(df.columns):\n",
        "    df[\"pct_with_computer\"] = (df[\"with_computer\"] / df[\"hh_total_comp\"]).clip(0, 1)\n",
        "\n",
        "# Education shares for 25+ population\n",
        "if {\"edu_total_25p\",\"high_school\"}.issubset(df.columns):\n",
        "    df[\"hs_grad_share\"] = (df[\"high_school\"] / df[\"edu_total_25p\"]).clip(0, 1)\n",
        "if {\"edu_total_25p\",\"bachelors\"}.issubset(df.columns):\n",
        "    df[\"bachelor_share\"] = (df[\"bachelors\"] / df[\"edu_total_25p\"]).clip(0, 1)\n",
        "\n",
        "# ---- 8) Enhanced summary statistics ----\n",
        "def enhanced_summary(df, cols):\n",
        "    out = {}\n",
        "    for c in cols:\n",
        "        if c in df.columns:\n",
        "            s = df[c]\n",
        "            out[c] = {\n",
        "                \"count\": s.count(),\n",
        "                \"missing\": s.isna().sum(),\n",
        "                \"mean\": s.mean(),\n",
        "                \"std\": s.std(),\n",
        "                \"min\": s.min(),\n",
        "                \"25%\": s.quantile(0.25),\n",
        "                \"50%\": s.median(),\n",
        "                \"75%\": s.quantile(0.75),\n",
        "                \"max\": s.max(),\n",
        "                \"zeros\": (s == 0).sum() if s.notna().any() else np.nan,\n",
        "            }\n",
        "    return pd.DataFrame(out).T\n",
        "\n",
        "summary_cols = list({\n",
        "    \"median_income\",\"total_population\",\"hh_total_inet\",\"hh_total_comp\",\n",
        "    \"no_internet\",\"with_computer\",\"pct_no_internet\",\"pct_with_computer\",\n",
        "    \"hs_grad_share\",\"bachelor_share\"\n",
        "} & set(df.columns))  # keep only those that exist\n",
        "\n",
        "summary_df = enhanced_summary(df, summary_cols)\n",
        "display(summary_df.round(3))\n"
      ],
      "metadata": {
        "id": "hSYGS3WFvxTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "from us import states\n",
        "\n",
        "# 0) If your df still has raw ACS codes, rename using your 'variables' dict\n",
        "# (Make sure your variables dict includes the denominators below)\n",
        "variables = {\n",
        "    \"B28002_001E\": \"hh_total_inet\",      # <-- add this\n",
        "    \"B28002_013E\": \"no_internet\",\n",
        "    \"B28001_001E\": \"hh_total_comp\",      # <-- and this\n",
        "    \"B28001_002E\": \"with_computer\",\n",
        "    \"B01003_001E\": \"total_population\",\n",
        "    # ... any others you pulled\n",
        "}\n",
        "# Only rename columns that are present\n",
        "df = df.rename(columns={k:v for k,v in variables.items() if k in df.columns}).copy()\n",
        "\n",
        "# 1) Make sure types are numeric\n",
        "for c in [\"no_internet\",\"with_computer\",\"hh_total_inet\",\"hh_total_comp\",\"total_population\"]:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# 2) Quick sanity check: what’s still missing?\n",
        "needed_for_pct = {\"no_internet\",\"hh_total_inet\"}\n",
        "missing = needed_for_pct - set(df.columns)\n",
        "print(\"Missing needed columns:\", missing)\n",
        "\n",
        "if missing:\n",
        "    raise KeyError(\n",
        "        f\"You're missing {missing}. Go back to the data-pull cell and include \"\n",
        "        f\"ACS codes B28002_013E (no_internet) AND B28002_001E (hh_total_inet). \"\n",
        "        f\"Re-run the pull, then re-run this cell.\"\n",
        "    )\n",
        "\n",
        "# 3) Aggregate by state (weighted % = sum(numerators)/sum(denominators))\n",
        "fips2name = {s.fips: s.name for s in states.STATES}\n",
        "state_summary = (\n",
        "    df.groupby(\"state\", dropna=False)\n",
        "      .agg(no_internet   = (\"no_internet\",   \"sum\"),\n",
        "           hh_total_inet = (\"hh_total_inet\", \"sum\"),\n",
        "           with_computer = (\"with_computer\",\"sum\") if \"with_computer\" in df.columns else (\"no_internet\",\"sum\"),\n",
        "           hh_total_comp = (\"hh_total_comp\",\"sum\") if \"hh_total_comp\" in df.columns else (\"no_internet\",\"sum\"),\n",
        "           total_population=(\"total_population\",\"sum\") if \"total_population\" in df.columns else (\"no_internet\",\"sum\"))\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "state_summary[\"state_name\"] = state_summary[\"state\"].map(fips2name)\n",
        "state_summary[\"Pct_No_Internet\"] = 100 * state_summary[\"no_internet\"] / state_summary[\"hh_total_inet\"]\n",
        "state_summary = state_summary.sort_values(\"Pct_No_Internet\", ascending=False)\n",
        "\n",
        "cols_show = [\"state_name\",\"Pct_No_Internet\",\"no_internet\",\"hh_total_inet\"]\n",
        "print(\"Top 5 States with Highest % of Households Without Internet:\")\n",
        "print(state_summary[cols_show].head(5).to_string(index=False))\n",
        "\n",
        "print(\"\\nTop 5 States with Lowest % of Households Without Internet:\")\n",
        "print(state_summary[cols_show].tail(5).to_string(index=False))\n"
      ],
      "metadata": {
        "id": "fO3_YBseuz0f",
        "outputId": "1a71c0bd-7a67-43ef-d095-51addd5b5a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing needed columns: {'hh_total_inet'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"You're missing {'hh_total_inet'}. Go back to the data-pull cell and include ACS codes B28002_013E (no_internet) AND B28002_001E (hh_total_inet). Re-run the pull, then re-run this cell.\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-681328728.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     raise KeyError(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;34mf\"You're missing {missing}. Go back to the data-pull cell and include \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;34mf\"ACS codes B28002_013E (no_internet) AND B28002_001E (hh_total_inet). \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"You're missing {'hh_total_inet'}. Go back to the data-pull cell and include ACS codes B28002_013E (no_internet) AND B28002_001E (hh_total_inet). Re-run the pull, then re-run this cell.\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52CLnHGw7qoX"
      },
      "source": [
        "### 4. Modeling and Evaluation\n",
        "---\n",
        "*(Describe and present the analytic models built on the data and evaluate the performance of the models for solving the problem)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1fthHN27qoX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REiq9oR57qoX"
      },
      "source": [
        "### 5. Conclusion\n",
        "---\n",
        "*(Briefly describe what you have done and what you discovered. Discuss any shortcomings of the process and results. Propose future work. **Finally, discuss the lessons learned from doing the project**.)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCHTiT-u7qoX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5tOZ3Wm7qoX"
      },
      "source": [
        "### 6. References"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiMlqsKz7qoX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fIbMSMw7qoX"
      },
      "source": [
        "---\n",
        "# Use the following requirements for preparing your project:\n",
        "\n",
        "## DO NOT DELETE THE CELLS BELLOW"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Requirements\n",
        "\n",
        "This final project examines the level of knowledge the students have learned from the course. The following course outcomes will be checked against the content of the report:\n",
        "\n",
        "Upon successful completion of this course, a student will be able to:\n",
        "* observe and explore a variety of quantitative methods for data analysis;\n",
        "* understand methods’ evaluation techniques to interpret their output;\n",
        "* implement and evaluate methods to gain technical experience with data; and\n",
        "* reproducibly execute an analytic project and represent/communicate its results faithfully.\n",
        "\n",
        "** Marking will be foucsed on both presentation and content.**\n",
        "\n",
        "## Written Presentation Requirements\n",
        "The report will be judged on the basis of visual appearance, grammatical correctness, and quality of writing, as well as its contents. Please make sure that the text of your report is well-structured, using paragraphs, full sentences, and other features of well-written presentation.\n",
        "\n",
        "## Technical Content:\n",
        "* Is the problem well defined and described thoroughly?\n",
        "* Is the size and complexity of the data set used in this project comparable to that of the example data sets used in the lectures and assignments?\n",
        "* Did the report describe the charactriatics of the data?\n",
        "* Did the report describe the goals of the data analysis?\n",
        "* Did the analysis conduct exploratory analyses on the data?\n",
        "* Did the analysis build analysis models of the data and evaluated the performance of the models?\n",
        "* Overall, what is the rating of this project?"
      ],
      "metadata": {
        "id": "eG_kYs25sA9F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYn3mvol7qoX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}